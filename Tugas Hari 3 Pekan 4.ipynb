{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrQVcF-ldGWQ"
   },
   "source": [
    "<h1> Soal 1: Pemahaman Tentang Model Evaluasi</h1>\n",
    "\n",
    "Jawab pertanyaan di bawah ini dengan bahasa masing-masing?\n",
    "\n",
    "1. Apa perbedaan antara data latih, data validasi, dan data test?\n",
    "2. Bagaimana cara kita menilai performa suatu model?\n",
    "3. Apa itu Confusion Matrix? Jelaskan secara lengkap!\n",
    "4. Apa itu Classification Report dari sklearn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sr6D5UIhgpwO"
   },
   "source": [
    "Jawab:\n",
    "1. Data Training, seperti namanya, data yang digunakan untuk training model. Data Validation, digunakan untuk proses validasi model dan mencegah overfitting. Data Testing, digunakan untuk testing model, sebagai simulasi penggunaan model pada dunia nyata.\n",
    "2. Untuk mengevaluasi kinerja suatu model tidak hanya ditentukan oleh akurasi saja. Banyak cara lain yang dapat digunakan untuk menilai performa dari suatu model, diantaranya:\n",
    "- Klasifikasi (classification metrics): accuracy, precision, recall, F1-score, ROC, AUC, dan lainnya.\n",
    "- Regresi (regression metrics) : MSE, MAE, dan lainnya.\n",
    "- Klastering (clustering metrics): Silhouette Coefficient, Davies-Bouldin Index, Dunn Index, dan lainnya.\n",
    "3. Confusion matrix merupakan salah satu metode yang dapat digunakan untuk mengukur kinerja suatu metode klasifikasi. Pada dasarnya confusion matrix mengandung informasi yang membandingkan hasil klasifikasi yang dilakukan oleh sistem dengan hasil klasifikasi yang seharusnya.\n",
    "4. classification report dari sklearn menampilkan precision, recall, F1 Score, dan support scores untuk model. precision adalah kemampuan pengklasifikasi untuk tidak memberi label pada instance positif yang sebenarnya negatif. Untuk setiap kelas, ini didefinisikan sebagai rasio positif benar dengan jumlah true positive dan false positive. recall adalah kemampuan pengklasifikasi untuk menemukan semua contoh positif. Untuk setiap kelas, ini didefinisikan sebagai rasio true positive dengan jumlah true positive dan false negative. F1 Score adalah rata-rata presisi dan recall harmonik tertimbang sehingga skor terbaik adalah 1.0 dan yang terburuk adalah 0.0. Skor F1 lebih rendah dari ukuran akurasi karena mereka menanamkan presisi dan recall ke dalam perhitungannya. Sebagai aturan praktis, rata-rata tertimbang F1 harus digunakan untuk membandingkan model pengklasifikasi, bukan akurasi global. Support adalah jumlah kemunculan aktual kelas dalam kumpulan data yang ditentukan. Dukungan yang tidak seimbang dalam data pelatihan dapat menunjukkan kelemahan struktural dalam skor pengklasifikasi yang dilaporkan dan dapat menunjukkan perlunya pengambilan sampel bertingkat atau penyeimbangan ulang. Dukungan tidak berubah antar model melainkan mendiagnosis proses evaluasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uY-s7-KDgrkV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv2TVsgAdGWY"
   },
   "source": [
    "<h1>Soal 2: Aplikasi Model Evaluasi</h1>\n",
    "\n",
    "Kali ini kita akan menggunakan data untuk memprediksi kelangsungan hidup pasien yang telah mengalami operasi payudara. Dengan informasi yang dimiliki terkait pasien, kita akan membuat model untuk memprediksi apakah pasien akan bertahan hidup dalam waktu lebih dari 5 tahun atau tidak.\n",
    "\n",
    "Lebih Lengkapnya kalian bisa membaca informasi tentang dataset di link berikut: https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.names\n",
    "\n",
    "Buat model Klasifikasi (Model/Algoritma Bebas) untuk memprediksi status pasien dengan ketentuan sebagai berikut:\n",
    "\n",
    "1. Bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\n",
    "3. Pelajar tentang metrics roc_auc_score kemudian buatlah model dan evaluasi dengan menggunakan teknik cross-validation dengan scoring 'roc_auc'. Baca https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html untuk menggunakan metric roc_auc saat cross-validation.\n",
    "3. Berapa score rata2 dari model dengan teknik cross-validation tersebut?\n",
    "4. Prediksi data test dengan model yang telah kalian buat!\n",
    "5. Bagaimana hasil confusion matrix dari hasil prediksi tersebut?\n",
    "6. Bagaimana classification report dari hasil prediksi tersebut?\n",
    "5. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status positive?\n",
    "6. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status negatif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4UqaWyPdGWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrbPNGtHdGXV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Patient's Years  N_positive_ax  survival_status\n",
       "0     30               64              1                1\n",
       "1     30               62              3                1\n",
       "2     30               65              0                1\n",
       "3     31               59              2                1\n",
       "4     31               65              4                1\n",
       "..   ...              ...            ...              ...\n",
       "301   75               62              1                1\n",
       "302   76               67              0                1\n",
       "303   77               65              3                1\n",
       "304   78               65              1                2\n",
       "305   83               58              2                2\n",
       "\n",
       "[306 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dxYNPg7dGX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225\n",
       "2     81\n",
       "Name: survival_status, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survival_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W2amvZgdGYX"
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "x = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.25, random_state=21,  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_roc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.612280701754386"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_roc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 10],\n",
       "       [12,  8]], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred, labels=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 47\n",
    "FN = 10\n",
    "FP = 12\n",
    "TN = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.82      0.81        57\n",
      "           2       0.44      0.40      0.42        20\n",
      "\n",
      "    accuracy                           0.71        77\n",
      "   macro avg       0.62      0.61      0.62        77\n",
      "weighted avg       0.71      0.71      0.71        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7966101694915254"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data possitive\n",
    "precision = TP/(TP+FP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245614035087719"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = TP/(TP+FN)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103448275862069"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score = 2*precision*recall/(precision+recall)\n",
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TN/(TN+FN)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = TN/(TN+FP)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4210526315789474"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score = 2*precision*recall/(precision+recall)\n",
    "f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6v_dgoN-7wL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teekoyIw--g2"
   },
   "source": [
    "<h1> Soal 3: Pemahaman Tentang Model Selection</h1>\n",
    "\n",
    "Jelaskan dengan bahasa sendiri!\n",
    "\n",
    "1. Apa itu Bias dan Variance?\n",
    "2. Apa itu Overfitting dan Underfitting?\n",
    "3. Apa yang bisa kita lakukan untuk mengatur kompleksitas dari model?\n",
    "4. Bagaimana model yang baik?\n",
    "5. Kapan kita menggunakan GridSearchcv dan kapan menggunakan RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a1l4RNf_FcU"
   },
   "source": [
    "Jawab:\n",
    "1. Bias\n",
    "Bias adalah perbedaan antara rata rata hasil prediksi dari model ML yang kita develop dengan data nilai yang sebenarnya. Bias yang tinggi dikarenakan dalam pembangunan model ML, dilakukan terlalu sederhan (oversimplified). Faktor penyebab lain dikarenakan model ML yang di develop terlalu tidak terlalu berinteraksi dengan training data. Bias seringkali terjadi dalam development sistem machine learning.\n",
    "Variance\n",
    "Variance adalah variabel dari prediksi model untuk data tertentu dimana memberikan kita informasi perserbaran data kita. Model yang memiliki variance tinggi sangat memperhatikan hanya pada train data. High variance model, perform baik di train data. Tetapi jika disuguhkan data baru yang belum pernah ditemukan di train data. Model tersebut tidak dapat mengeneralisasikan secara baik dari identifikasi data baru tersebut. Alhasil model memprediksi dengan keliru.\n",
    "2. Underfitting terjadi ketika model tidak bisa melihat logika dibelakang data, hingga tidak bisa melakukan prediksi dengan tepat, baik untuk dataset training maupun dataset lain yang serupa. Underfitting model akan memiliki high loss dan akurasi rendah.\n",
    "Overfitting terjadi karena model yang dibuat terlalu fokus pada training dataset tertentu, hingga tidak bisa melakukan prediksi dengan tepat jika diberikan dataset lain yang serupa. Overfitting biasanya akan menangkap data noise yang seharusnya diabaikan. Overfitting model akan memiliki low loss dan akurasi rendah.\n",
    "3. Model bias membutuhkan lebih banyak kompleksitas dalam pemilihan Model sedangkan model yang sangat bervariasi membutuhkan penurunan kompleksitas dalam pemilihan model. Teknik pengaturan dapat membantu kita dalam mengidentifikasi tingkat kompleksitas model yang tepat dan melalui teknik ini kita dapat mengatasi kedua masalah tersebut.\n",
    "4. model yang baik adalah model yang dapat meng-estimasi satu himpunan nilai-nilai parameter yang unik untuk satu himpunan data yang tertentu. dengan demikian, suatu model yang tidak mempunyai identifiability berarti model tersebut dapat meng-estimasi lebih dari satu himpunan nilai parameter yang konsisten dengan data.\n",
    "5. GridSearchcv mencoba semua kombinasi Hyperparameter yang mungkin. RandomizedSearchCV memilih beberapa secara random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Svj_cgxF_IZv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hkh-PeRL_LZp"
   },
   "source": [
    "<h1> Soal 4: Aplikasi Model Selection</h1>\n",
    "\n",
    "1. Bagi kedua data berikut ini menjadi data training dan data test dengan test_size=0.25.\n",
    "2. Gunakan algoritma KNN sebagai model classifier.\n",
    "3. Gunakan fungsi GridSearchCV untuk hyperparameter tuning dan model selection.\n",
    "4. jumlah fold bebas!, gunakan scoring 'roc_auc'\n",
    "5. Definisikan kombinasi hyperparameter untuk model selection dengan GridSearchCV. kombinasi Hyperparameter bebas, baca lagi dokumentasi KNN di link berikut https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html untuk memahami lagi jenis2 hyperparameter di algorithma KNN.\n",
    "6. Latih model terhadap data training.\n",
    "7. Apa hyperparameter terbaik untuk kombinasi hyperparameter kalian?\n",
    "8. Berapa score validasi terbaik dari model tersebut?\n",
    "9. Prediksi probabilitasi output dari model yang telah di buat terhadap data test. note : gunakan method .predict_proba() untuk menghasilkan output probabilitas\n",
    "10. Perhatikan bahwa hasil prediksi ada 2, dimana masing2 adalah nilai probabilitas untuk setiap class label. Ambil nilai probabilitas pasien phositive meninggal dalam waktu kurang dari 5 tahun. note : gunakan bantuan attirubte .classes_ untuk mengetahui urutan label dari hasil prediksi probabilitas.\n",
    "11. Berapa nilai score roc_auc untuk data test?\n",
    "12. Apakah model anda termasuk baik, overtting, atau underfitting?\n",
    "13. Ulangi tahap di atas namun kali ini menggunakan algoritma DecisionTreeClassifier dan kalian bisa menggunakan RandomizedSearchCV apabila process training lama. pelajari algoritma DecisionTreeClassifier di linkberikut: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\n",
    "14. Bandingkan scorenya dengan Algoritma KNN, mana yang lebih baik?\n",
    "\n",
    "Note : Data Science adalah experiment, sangat di dimungkinkan memerlukan beberapa kali percobaan untuk mendapatkan hasil yang terbaik! Happy Coding :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_zK8Mqb-9Z6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb-AD43R_V_d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc1dEGO_XU2"
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=37, weights='uniform')\n",
    "\n",
    "X = df.drop('survival_status', axis=1)\n",
    "Y = df['survival_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning from data\n",
    "model_knn.fit(X_train, Y_train)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size=0.25, random_state=21,  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                         'weights': ['distance', 'uniform']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':np.arange(5,50), 'weights':['distance', 'uniform']}\n",
    "\n",
    "gscv = GridSearchCV(model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "gscv.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 37, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7713379164463248"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred= model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606140350877193"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_roc = roc_auc_score(Y_test, Y_pred)\n",
    "cv_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Hari 3 Pekan 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
